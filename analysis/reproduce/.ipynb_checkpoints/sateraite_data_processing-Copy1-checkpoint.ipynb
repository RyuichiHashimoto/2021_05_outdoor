{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "649d1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from external_lib.gnss_derived import load_derived_file,load_gnss_raw_file,correct_millisSinceGpsEpoch,extract_between_time,add_signalType_to_gnss_info\n",
    "\n",
    "from lib.noglobal import noglobal\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import scipy.optimize as opt\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "677f8b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def ecef2lla(x, y, z):\n",
    "    # x, y and z are scalars or vectors in meters\n",
    "    x = np.array([x]).reshape(np.array([x]).shape[-1], 1)\n",
    "    y = np.array([y]).reshape(np.array([y]).shape[-1], 1)\n",
    "    z = np.array([z]).reshape(np.array([z]).shape[-1], 1)\n",
    "\n",
    "    a=6378137\n",
    "    a_sq=a**2\n",
    "    e = 8.181919084261345e-2\n",
    "    e_sq = 6.69437999014e-3\n",
    "\n",
    "    f = 1/298.257223563\n",
    "    b = a*(1-f)\n",
    "\n",
    "    # calculations:\n",
    "    r = np.sqrt(x**2 + y**2)\n",
    "    ep_sq  = (a**2-b**2)/b**2\n",
    "    ee = (a**2-b**2)\n",
    "    f = (54*b**2)*(z**2)\n",
    "    g = r**2 + (1 - e_sq)*(z**2) - e_sq*ee*2\n",
    "    c = (e_sq**2)*f*r**2/(g**3)\n",
    "    s = (1 + c + np.sqrt(c**2 + 2*c))**(1/3.)\n",
    "    p = f/(3.*(g**2)*(s + (1./s) + 1)**2)\n",
    "    q = np.sqrt(1 + 2*p*e_sq**2)\n",
    "    r_0 = -(p*e_sq*r)/(1+q) + np.sqrt(0.5*(a**2)*(1+(1./q)) - p*(z**2)*(1-e_sq)/(q*(1+q)) - 0.5*p*(r**2))\n",
    "    u = np.sqrt((r - e_sq*r_0)**2 + z**2)\n",
    "    v = np.sqrt((r - e_sq*r_0)**2 + (1 - e_sq)*z**2)\n",
    "    z_0 = (b**2)*z/(a*v)\n",
    "    h = u*(1 - b**2/(a*v))\n",
    "    phi = np.arctan((z + ep_sq*z_0)/r)\n",
    "    lambd = np.arctan2(y, x)\n",
    "\n",
    "    return phi*180/np.pi, lambd*180/np.pi, h\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@noglobal()\n",
    "def add_prev_info(derived_df):    \n",
    "    s = derived_df.copy()\n",
    "    time_stamp_prev_hashmap = {};\n",
    "    millis_list = s[\"millisSinceGpsEpoch\"].unique().tolist();\n",
    "    for idx in range(len(millis_list)):    \n",
    "        time_stamp_prev_hashmap[millis_list[idx]] = millis_list[max(idx-1,0)]\n",
    "        \n",
    "    s[\"prev_millisSinceGpsEpoch\"] = s[\"millisSinceGpsEpoch\"].apply(lambda x: time_stamp_prev_hashmap[x])\n",
    "    s[\"time_delta_sec\"] = (s[\"millisSinceGpsEpoch\"] - s[\"prev_millisSinceGpsEpoch\"])/1000    \n",
    "    return s;\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "@noglobal()\n",
    "def distance(sat_pos, x):\n",
    "    sat_pos_diff = sat_pos.copy(deep=True)\n",
    "                            \n",
    "    sat_pos_diff['xSatPosMRotated'] = sat_pos_diff['xSatPosMRotated'] - x[0]\n",
    "    sat_pos_diff['ySatPosMRotated'] = sat_pos_diff['ySatPosMRotated'] - x[1]\n",
    "    sat_pos_diff['zSatPosMRotated'] = sat_pos_diff['zSatPosMRotated'] - x[2]\n",
    "    \n",
    "    return sat_pos_diff[\"uncertaintyWeight\"]*(np.sqrt((sat_pos_diff[\"xSatPosMRotated\"]**2 + sat_pos_diff[\"ySatPosMRotated\"]**2 + sat_pos_diff[\"zSatPosMRotated\"]**2))+ x[3] - sat_pos_diff[\"correctedPrM\"])\n",
    "\n",
    "@noglobal()\n",
    "def distance_fixed_satpos(x,train_df):    \n",
    "    return distance(train_df[['xSatPosMRotated', 'ySatPosMRotated', 'zSatPosMRotated', 'correctedPrM', 'uncertaintyWeight']], x)\n",
    "\n",
    "@noglobal()\n",
    "def predict_by_satelite_per_time(list_):\n",
    "    key = list_[0]\n",
    "    each_df = list_[1]\n",
    "    \n",
    "    \n",
    "                \n",
    "    x0= [0,0,0,0]        \n",
    "    opt_res = opt.least_squares(lambda x: distance_fixed_satpos(x,each_df), x0)\n",
    "    \n",
    "    opt_res_pos = opt_res[\"x\"]\n",
    "    wls_estimated_pos = ecef2lla(*opt_res_pos[:3])\n",
    "    wls_estimated_pos = np.squeeze(wls_estimated_pos)\n",
    "    return [key, wls_estimated_pos[0],wls_estimated_pos[1],wls_estimated_pos[2]]\n",
    "    \n",
    "@noglobal()\n",
    "def multi(function_name,exe_list):\n",
    "    p = mp.Pool(mp.cpu_count()-1);\n",
    "    retult = p.map(function_name,exe_list);\n",
    "    p.close();\n",
    "    return retult    \n",
    "\n",
    "@noglobal()    \n",
    "def erase_outlier_signals(corrected_derived_df):\n",
    "    corrected_derived_df['receivedSvTimeInGpsMillis']  = corrected_derived_df['receivedSvTimeInGpsNanos'] / 1e6    \n",
    "    corrected_derived_df[\"delta\"] = (corrected_derived_df['millisSinceGpsEpoch'] - corrected_derived_df['receivedSvTimeInGpsMillis'] ).astype(int)        \n",
    "    delta_millis = corrected_derived_df['millisSinceGpsEpoch'] - corrected_derived_df['receivedSvTimeInGpsNanos'] / 1e6    \n",
    "    where_good_signals = (delta_millis > 0) & (delta_millis < 300)\n",
    "    return corrected_derived_df[where_good_signals].copy()            \n",
    "    \n",
    "        \n",
    "@noglobal()\n",
    "def predict_by_gnss_data(df):\n",
    "                                          \n",
    "    #df = erase_outlier_signals(df)\n",
    "                    \n",
    "    light_speed = 299_792_458                \n",
    "    \n",
    "    #df['correctedPrM'] = df[\"rawPrM\"] +  df[\"satClkBiasM\"]  - df[\"isrbM\"] - df[\"ionoDelayM\"] - df[\"tropoDelayM\"]\n",
    "            \n",
    "    ### Rotating the Satellite Reference Frame\n",
    "    df['transmissionTimeSeconds'] = df['correctedPrM'] / light_speed    \n",
    "    \n",
    "    \n",
    "    omega_e = 7.2921151467e-5\n",
    "    df[\"xSatPosMRotated\"] = np.cos(omega_e * df['transmissionTimeSeconds']) * df['xSatPosM'] + np.sin(omega_e * df['transmissionTimeSeconds']) * df['ySatPosM']\n",
    "    df[\"ySatPosMRotated\"] = - np.sin(omega_e * df['transmissionTimeSeconds']) * df['xSatPosM'] + np.cos(omega_e * df['transmissionTimeSeconds']) * df['ySatPosM']\n",
    "    df['zSatPosMRotated'] = df['zSatPosM']\n",
    "    \n",
    "    #display(df_train)\n",
    "    df['uncertaintyWeight'] = 1 / df['rawPrUncM']    \n",
    "                                \n",
    "    test_list = [];        \n",
    "    exe_list = [[key,each_df]  for key,each_df in df.groupby(\"millisSinceGpsEpoch\")];        \n",
    "    \n",
    "    num = multi(predict_by_satelite_per_time,exe_list)\n",
    "    \n",
    "    return pd.DataFrame(np.array(num),columns=[\"millisSinceGpsEpoch\",\"x_pred\",\"y_pred\",\"z_pred\"]);\n",
    "\n",
    "    \n",
    "#collection,phone = df_baseline[\"phone\"].unique()[0].split(\"_\")\n",
    "\n",
    "#collection = \"2021-04-29-US-SJC-2\"\n",
    "#phone = \"Pixel4\"\n",
    "#c = df_baseline[df_baseline[\"phone\"] == collection+\"_\"+phone];\n",
    "\n",
    "#predict_result = predict_by_gnss_data(collection,phone);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a0c66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-14-US-MTV-1  2020-07-08-US-MTV-1  2021-01-05-US-SVL-2\r\n",
      "2020-05-14-US-MTV-2  2020-07-17-US-MTV-1  2021-03-10-US-SVL-1\r\n",
      "2020-05-21-US-MTV-1  2020-07-17-US-MTV-2  2021-04-15-US-MTV-1\r\n",
      "2020-05-21-US-MTV-2  2020-08-03-US-MTV-1  2021-04-22-US-SJC-1\r\n",
      "2020-05-29-US-MTV-1  2020-08-06-US-MTV-2  2021-04-26-US-SVL-1\r\n",
      "2020-05-29-US-MTV-2  2020-09-04-US-SF-1   2021-04-28-US-MTV-1\r\n",
      "2020-06-04-US-MTV-1  2020-09-04-US-SF-2   2021-04-28-US-SJC-1\r\n",
      "2020-06-05-US-MTV-1  2021-01-04-US-RWC-1  2021-04-29-US-MTV-1\r\n",
      "2020-06-05-US-MTV-2  2021-01-04-US-RWC-2  2021-04-29-US-SJC-2\r\n",
      "2020-06-11-US-MTV-1  2021-01-05-US-SVL-1\r\n"
     ]
    }
   ],
   "source": [
    "!ls /work/data/input/google-smartphone-decimeter-challenge/train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5301c4",
   "metadata": {},
   "source": [
    "### load processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fcb5fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#derived_df = load_derived_file(collection,phone,mode)\n",
    "#gnss_df = load_gnss_raw_file(collection,phone,mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81449886",
   "metadata": {},
   "source": [
    "### first processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8312a353",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a911533492cc4aa0b658b3fe43a5d17f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2888 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-eb7471e852c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mcollection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"2021-04-22-US-SJC-1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mphone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Pixel4\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mmerged_df\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mgenerate_merged_df\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mphone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-5-eb7471e852c0>\u001b[0m in \u001b[0;36mgenerate_merged_df\u001b[0;34m(collection, phone, mode)\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"asdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mtmp_merged_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextracted_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"svid\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mextracted_gnss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"left\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"tmp\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_derived\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"_gnss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     )\n\u001b[0;32m---> 89\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m             \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m             \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m         )\n\u001b[1;32m    699\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             b = make_block(\n\u001b[0;32m---> 83\u001b[0;31m                 \u001b[0m_concatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0mplacement\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplacement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mndim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    313\u001b[0m     to_concat = [\n\u001b[1;32m    314\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     ]\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    313\u001b[0m     to_concat = [\n\u001b[1;32m    314\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m     ]\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malgos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake_nd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, allow_fill)\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1756\u001b[0m     func = _get_take_nd_function(\n\u001b[0;32m-> 1757\u001b[0;31m         \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask_info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1758\u001b[0m     )\n\u001b[1;32m   1759\u001b[0m     \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36m_get_take_nd_function\u001b[0;34m(ndim, arr_dtype, out_dtype, axis, mask_info)\u001b[0m\n\u001b[1;32m   1536\u001b[0m ):\n\u001b[1;32m   1537\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1538\u001b[0;31m         \u001b[0mtup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0marr_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1539\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1540\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_take_1d_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/_dtype.py\u001b[0m in \u001b[0;36m_name_get\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_name_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m     \u001b[0;31m# provides dtype.name.__get__, documented as returning a \"bit name\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "#merged_df.shape\n",
    "\n",
    "@noglobal()\n",
    "def generate_merged_df(collection,phone,mode):\n",
    "    \n",
    "    extracted_columns = ['xSatPosM', 'ySatPosM', 'zSatPosM',\"rawPrUncM\",\"rawPrM\",\"satClkBiasM\",\"isrbM\",\"ionoDelayM\",\"tropoDelayM\",\"receivedSvTimeInGpsNanos\",\"signalType_gnss\",\"svid_gnss\",\"constellationName_gnss\",\"carrierFrequencyHz\",\"signalType_svid_gnss\",\"AccumulatedDeltaRangeMeters\",\"correctedPrM\",\"BiasUncertaintyNanos\",\"Cn0DbHz\"]                                \n",
    "    \n",
    "    \n",
    "    root = \"/work/data/input/google-smartphone-decimeter-challenge/\"\n",
    "    \n",
    "    derived_df = load_derived_file(collection,phone,mode)\n",
    "    gnss_df = load_gnss_raw_file(collection,phone,mode)\n",
    "    \n",
    "    correct_deriveddf = correct_millisSinceGpsEpoch(derived_df,gnss_df)\n",
    "    correct_deriveddf = add_prev_info(correct_deriveddf)\n",
    "    \n",
    "    \n",
    "    \n",
    "    gnss_df[\"signalType_svid\"] = gnss_df[\"signalType\"] + \"_\" + gnss_df[\"svid\"].astype(str)\n",
    "    correct_deriveddf[\"signalType_svid\"] = correct_deriveddf[\"signalType\"] + \"_\" + correct_deriveddf[\"svid\"].astype(str)\n",
    "    correct_deriveddf[\"tmp\"] = correct_deriveddf[\"signalType\"] + \"_\" + correct_deriveddf[\"svid\"].astype(str)\n",
    "    gnss_df[\"tmp\"] = gnss_df[\"signalType\"] + \"_\" + gnss_df[\"svid\"].astype(str)\n",
    "    \n",
    "    correct_deriveddf['correctedPrM'] = correct_deriveddf[\"rawPrM\"] +  correct_deriveddf[\"satClkBiasM\"]  - correct_deriveddf[\"isrbM\"] - correct_deriveddf[\"ionoDelayM\"] - correct_deriveddf[\"tropoDelayM\"]    \n",
    "    \n",
    "    list_per_millis = [];\n",
    "    idx = -1;\n",
    "    bef_time = 0;\n",
    "        \n",
    "    for now_time,extracted_df in tqdm(correct_deriveddf.groupby(\"millisSinceGpsEpoch\")):        \n",
    "        idx = idx+1;\n",
    "                \n",
    "        extracted_gnss = extract_between_time(gnss_df,bef_time,now_time)        \n",
    "        \n",
    "        extracted_df = extracted_df.drop_duplicates(subset=[\"tmp\"],keep=\"first\")            \n",
    "        extracted_gnss = extracted_gnss.drop_duplicates(subset=[\"tmp\"],keep=\"first\")                \n",
    "\n",
    "        if (not idx == 0):\n",
    "            if(extracted_gnss.isnull().sum().sum() == extracted_gnss.shape[0]*extracted_gnss.shape[1]):        \n",
    "                display(extracted_gnss)\n",
    "                raise Exception(\"asdf\");    \n",
    "\n",
    "        tmp_merged_df = pd.merge(extracted_df.sort_values(\"svid\"),extracted_gnss,how = \"left\",on=\"tmp\",suffixes=[\"_derived\",\"_gnss\"])            \n",
    "        \n",
    "        \n",
    "        m = tmp_merged_df.set_index(\"tmp\")[extracted_columns]    \n",
    "        m = m.rename(columns = {\"constellationName_gnss\":\"constellationName\",\"svid_gnss\":\"svid\",\"signalType_gnss\":\"signalType\",\"signalType_svid_gnss\":\"signalType_svid\"})\n",
    "        m = m.T\n",
    "        \n",
    "        m[\"index_name\"] = m.index\n",
    "        m[\"index\"] = idx    \n",
    "        m[\"millisSinceGpsEpoch\"] = now_time;    \n",
    "        m = m.set_index(\"index\")\n",
    "        bef_time = now_time\n",
    "\n",
    "        list_per_millis.append(m)\n",
    "    merged_df = pd.concat(list_per_millis);\n",
    "    merged_df[[\"phone\",\"collectionName\",\"phoneName\"]] = [collection+\"_\"+phone,collection,phone];\n",
    "        \n",
    "        \n",
    "    return merged_df;\n",
    "    \n",
    "\n",
    "collection = \"2021-04-22-US-SJC-1\"\n",
    "phone = \"Pixel4\"    \n",
    "merged_df  = generate_merged_df(collection,phone,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3977a6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def extract_df_by_col(df,column):\n",
    "    \n",
    "    ret_df = df.copy();\n",
    "    ret_df = ret_df[ret_df[\"index_name\"] == column]\n",
    "            \n",
    "    ret_df[\"delta_t_sec\"]  = (ret_df[\"millisSinceGpsEpoch\"] - ret_df.shift(1)[\"millisSinceGpsEpoch\"])/1000\n",
    "    erase_list = [\"index_name\",'phone', 'collectionName', 'phoneName']\n",
    "    \n",
    "    for k in erase_list:\n",
    "        del ret_df[k]\n",
    "        \n",
    "    ret_df = ret_df.astype(\"float64\")\n",
    "    ret_df[\"millisSinceGpsEpoch\"] = ret_df[\"millisSinceGpsEpoch\"].astype(\"int64\")\n",
    "    \n",
    "    prev_ret_df = ret_df.shift(1)\n",
    "        \n",
    "    return ret_df,prev_ret_df;\n",
    "\n",
    "@noglobal()\n",
    "def get_target_columns(df):\n",
    "    return [k for k in df.columns.tolist() if not ( (k == \"millisSinceGpsEpoch\") or (k == \"delta_t_sec\"))]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25f613ab",
   "metadata": {},
   "source": [
    "@noglobal()\n",
    "def create_adr_mps(Accm_df,prev_Accm_df,IonoDelayM_df,prev_IonoDelayM_df,TropoDelayM_df,prev_TropoDelayM_df,SatClkBiasM_df,prev_SatClkBiasM_df):\n",
    "    target_columns = get_target_columns(Accm_df);\n",
    "    \n",
    "    hash_map = {}\n",
    "\n",
    "    for k in target_columns:\n",
    "        corrected_delta_adr_mps = (Accm_df[k].to_numpy() -prev_Accm_df[k].to_numpy())/Accm_df[\"delta_t_sec\"].to_numpy()\n",
    "\n",
    "        delta_atmos_delay_mps = ((IonoDelayM_df[k] + TropoDelayM_df[k]).to_numpy() - (prev_IonoDelayM_df[k] + prev_TropoDelayM_df[k]).to_numpy())/IonoDelayM_df[\"delta_t_sec\"].to_numpy()    \n",
    "\n",
    "        ft_mps = (SatClkBiasM_df[k].to_numpy() - prev_SatClkBiasM_df[k].to_numpy()) /SatClkBiasM_df[\"delta_t_sec\"].to_numpy();\n",
    "\n",
    "        corrected_delta_adr_mps = corrected_delta_adr_mps + delta_atmos_delay_mps + ft_mps\n",
    "        hash_map[k] = corrected_delta_adr_mps\n",
    "    return hash_map\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#adr_hashmap = create_adr_mps(Accm_df,prev_Accm_df,IonoDelayM_df,prev_IonoDelayM_df,TropoDelayM_df,prev_TropoDelayM_df,SatClkBiasM_df,prev_SatClkBiasM_df);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e86d8c",
   "metadata": {
    "hide_input": false
   },
   "source": [
    "import math\n",
    "#adr_hashmap\n",
    "for key in adr_hashmap:\n",
    "    \n",
    "    fixed_list = [0]*len(adr_hashmap[key]);        \n",
    "    adder_list = adr_hashmap[key].tolist()\n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in range(len(fixed_list)):\n",
    "        if (math.isnan(adder_list[i])):\n",
    "            fixed_list[i] = math.nan\n",
    "        elif (adder_list[i] < 1000 and adder_list[i] > -1000):\n",
    "            fixed_list[i] = adder_list[i]\n",
    "        else:            \n",
    "            fixed_list[i] = fixed_list[-1]\n",
    "        \n",
    "    \n",
    "    #print(fixed_list)\n",
    "    #\n",
    "    adr_hashmap[key] = np.array(fixed_list)\n",
    "    \n",
    "    \n",
    "\n",
    "pd.DataFrame({\"test\":adr_hashmap[list(adr_hashmap.keys())[1]]})[\"test\"].plot()\n",
    "#ccm_df[\"GAL_E5A_2\"].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15225665",
   "metadata": {},
   "source": [
    "### add adr cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17661e76",
   "metadata": {},
   "source": [
    "import math\n",
    "\n",
    "@noglobal()\n",
    "def add_adr_info_to_all_cols(df,adr_hash_map):\n",
    "        \n",
    "    ret_df = df.copy()\n",
    "    target_cols = get_target_columns(df);\n",
    "\n",
    "    for sate_id in tqdm(target_cols):        \n",
    "        addr_list = adr_hash_map[sate_id].tolist()\n",
    "        corrected_df_list = df[sate_id].tolist();\n",
    "        null_first_flag = True;\n",
    "        \n",
    "        before_value = math.nan;\n",
    "        \n",
    "        result = [0]*len(corrected_df_list);\n",
    "                \n",
    "        for time_idx in range(len(corrected_df_list)):                \n",
    "            \n",
    "            if (math.isnan(before_value)):\n",
    "                value = corrected_df_list[time_idx]                        \n",
    "            else:            \n",
    "                value = before_value + addr_list[time_idx-1];                        \n",
    "                                        \n",
    "            result[time_idx] = value;\n",
    "            before_value = value;\n",
    "                    \n",
    "        ret_df[sate_id] = result  \n",
    "    return ret_df\n",
    "\n",
    "    \n",
    "\n",
    "#xSatPosM_df = add_adr_info_to_all_cols(xSatPosM_df,adr_hashmap)\n",
    "#ySatPosM_df = add_adr_info_to_all_cols(ySatPosM_df,adr_hashmap)\n",
    "#zSatPosM_df = add_adr_info_to_all_cols(zSatPosM_df,adr_hashmap)\n",
    "\n",
    "correctedPrM_df, prev_correctedPrM_df = extract_df_by_col(merged_df,correctedPrM)\n",
    "xSatPosM_df, _ = extract_df_by_col(merged_df,\"xSatPosM\")\n",
    "ySatPosM_df, _ = extract_df_by_col(merged_df,\"ySatPosM\")\n",
    "zSatPosM_df, _ = extract_df_by_col(merged_df,\"zSatPosM\")\n",
    "\n",
    "#xSatPosM_df = add_adr_info_to_all_cols(xSatPosM_df,adr_hashmap)\n",
    "#ySatPosM_df = add_adr_info_to_all_cols(ySatPosM_df,adr_hashmap)\n",
    "#zSatPosM_df = add_adr_info_to_all_cols(zSatPosM_df,adr_hashmap)\n",
    "correctedPrM_df = add_adr_info_to_all_cols(correctedPrM_df,adr_hashmap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01163b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#print(len(s[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2637e914",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def merge_satelite(df_list,label_list):\n",
    "    \n",
    "    if (not len(df_list) == len(label_list)):\n",
    "        raise Exception(\"specify mistake\");\n",
    "    elif (len(df_list) == 0):\n",
    "        raise Exception(\"There is no dataset\");\n",
    "            \n",
    "    target_cols = get_target_columns(df_list[0]);\n",
    "    pd_list = [];\n",
    "    \n",
    "    for idx,time in enumerate(tqdm(df_list[0][\"millisSinceGpsEpoch\"].unique())):\n",
    "        \n",
    "        each_time_pd_list = [];\n",
    "        \n",
    "        for name,target_df in zip(label_list,df_list):\n",
    "            tmp_df = target_df[target_df[\"millisSinceGpsEpoch\"] == time]\n",
    "            tmp_df.index = [name]\n",
    "            tmp_df = tmp_df[target_cols].T                \n",
    "            \n",
    "            each_time_pd_list.append(tmp_df);\n",
    "            \n",
    "        df_each_time = pd.concat(each_time_pd_list,axis=1);\n",
    "                    \n",
    "        df_each_time[\"millisSinceGpsEpoch\"] = time\n",
    "        df_each_time[\"index\"] = idx;\n",
    "        df_each_time = df_each_time.set_index(\"index\")\n",
    "                                \n",
    "        pd_list.append(df_each_time.dropna());\n",
    "    \n",
    "    return pd.concat(pd_list);\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1368c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_list = ['xSatPosM', 'ySatPosM', 'zSatPosM',\"rawPrUncM\",\"rawPrM\",\"satClkBiasM\",\"isrbM\",\"ionoDelayM\",\"tropoDelayM\",\"receivedSvTimeInGpsNanos\",\"carrierFrequencyHz\",\"AccumulatedDeltaRangeMeters\",\"BiasUncertaintyNanos\",\"Cn0DbHz\",\"correctedPrM\"]                                                   \n",
    "merged_df_list = [ extract_df_by_col(merged_df,add)[0]  for add in additional_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22809a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "correctedPrM_df = merged_df_list[-1].copy();\n",
    "ADR_df = merged_df_list[-4].copy();\n",
    "prev_ADR_df = ADR_df.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9366dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def add_adr_info_to_all_cols(df,ADR_df):\n",
    "        \n",
    "    ret_df = df.copy()\n",
    "    target_cols = get_target_columns(df);\n",
    "\n",
    "    M = 1000;\n",
    "    \n",
    "    for sate_id in tqdm(target_cols):        \n",
    "                \n",
    "        addr_list = ADR_df[sate_id].tolist()\n",
    "        corrected_df_list = df[sate_id].tolist();\n",
    "        null_first_flag = True;\n",
    "        \n",
    "        \n",
    "        result = [0]*len(corrected_df_list);        \n",
    "        result[0] = corrected_df_list[0]\n",
    "        \n",
    "        before_value = corrected_df_list[0];\n",
    "        before_adr = addr_list[0];\n",
    "                \n",
    "        for time_idx in range(1,len(corrected_df_list)):                \n",
    "                                                            \n",
    "            if (math.isnan(before_value)):\n",
    "                value = corrected_df_list[time_idx]                        \n",
    "            else:            \n",
    "                value = ((M-1)/M)*( before_value + addr_list[time_idx]-addr_list[time_idx-1] ) + (1/M)*corrected_df_list[time_idx]\n",
    "                                                                        \n",
    "            result[time_idx] = value;\n",
    "            before_value = value;\n",
    "                    \n",
    "        ret_df[sate_id] = result  \n",
    "    return ret_df\n",
    "\n",
    "s = add_adr_info_to_all_cols(correctedPrM_df,correctedPrM_df);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5247676",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_tips5(derived_df):\n",
    "    delta_millis = derived_df['millisSinceGpsEpoch'] - derived_df['receivedSvTimeInGpsNanos'] / 1e6\n",
    "    where_good_signals = (delta_millis > 0) & (delta_millis < 300)\n",
    "    return derived_df[where_good_signals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634d5df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "merged_df_list[-1] = s;\n",
    "    \n",
    "df = merge_satelite(merged_df_list,additional_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df8d255",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filterd = apply_tips5(df.copy())\n",
    "df_filterd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c0526",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predict_result = predict_by_gnss_data(df_filterd.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb757737",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = predict_result.copy()\n",
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2ce1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"2021-04-22-US-SJC-1\"\n",
    "phone = \"Pixel4\"    \n",
    "\n",
    "\n",
    "from external_lib.visualize import visualize_trafic\n",
    "output = output.rename(columns = {\"x_pred\":\"latDeg\",\"y_pred\":\"lngDeg\"})\n",
    "visualize_trafic(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea555db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = \"2021-04-22-US-SJC-1\"\n",
    "phone = \"Pixel4\"    \n",
    "rain_df = pd.read_csv(\"/work/data/input/google-smartphone-decimeter-challenge/baseline_locations_train.csv\")\n",
    "baseline_each_df = baseline_train_df[baseline_train_df[\"phone\"] == collection + \"_\" + phone];\n",
    "merged_df = pd.merge(merged_df,baseline_each_df[[\"millisSinceGpsEpoch\",\"latDeg\",\"lngDeg\"]],how=\"left\",on = \"millisSinceGpsEpoch\")\n",
    "#merged_df.head(3)\n",
    "\n",
    "#display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90550e4e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from external_lib.visualize import visualize_trafic\n",
    "\n",
    "v = s.copy()\n",
    "#v[\"time\"] = merged_df[\"millisSinceGpsEpoch\"].unique().tolist()\n",
    "\n",
    "#v[[\"latDeg\",\"lngDeg\"]] = v[[\"x_pred\",\"y_pred\"]] \n",
    "\n",
    "visualize_trafic(baseline_each_df)\n",
    "#v.loc[816,\"millisSinceGpsEpoch\"]\n",
    "\n",
    "#pe = merged_df[merged_df[\"millisSinceGpsEpoch\"] == 1274828302438]\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
