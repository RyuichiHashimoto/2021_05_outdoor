{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7d3380a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from lib.io import load_pickle_data\n",
    "from lib.noglobal import noglobal\n",
    "from lib.kalman_filter import generate_kalmanfilter,apply_kalmanfilter\n",
    "\n",
    "\n",
    "from external_lib.visualize import visualize_trafic\n",
    "from external_lib.evaluation_function import calc_haversine\n",
    "from external_lib.outlier_correlation import outlier_correlation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cda519f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_path = \"/work/data/input/selfmade_dataset/baseline_with_derived_data_v4/train.pkl\"\n",
    "train_df = load_pickle_data(train_df_path);\n",
    "train_df = train_df.rename(columns = {\"MillisSinceGpsEpoch\":\"millisSinceGpsEpoch\"})\n",
    "\n",
    "\n",
    "test_df_path = \"/work/data/input/selfmade_dataset/baseline_with_derived_data_v4/test.pkl\"\n",
    "test_df = load_pickle_data(test_df_path);\n",
    "test_df = test_df.rename(columns = {\"MillisSinceGpsEpoch\":\"millisSinceGpsEpoch\"})\n",
    "\n",
    "best_submission = \"/work/data/submission_list/baseline_with_merge_poitns_with_kalman/to_csv.csv\"\n",
    "best_sub = pd.read_csv(best_submission)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07838a3",
   "metadata": {},
   "source": [
    "## reject outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00f0fca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def add_distance_diff(arg_df):\n",
    "    df = arg_df.copy()\n",
    "    df['latDeg_prev'] = df['latDeg'].shift(1)\n",
    "    df['latDeg_next'] = df['latDeg'].shift(-1)\n",
    "    df['lngDeg_prev'] = df['lngDeg'].shift(1)\n",
    "    df['lngDeg_next'] = df['lngDeg'].shift(-1)\n",
    "    df['phone_prev'] = df['phone'].shift(1)\n",
    "    df['phone_next'] = df['phone'].shift(-1)\n",
    "    \n",
    "    df['dist_prev'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_prev'], df['lngDeg_prev'])\n",
    "    df['dist_next'] = calc_haversine(df['latDeg'], df['lngDeg'], df['latDeg_next'], df['lngDeg_next'])\n",
    "    \n",
    "    df.loc[df['phone']!=df['phone_prev'], ['latDeg_prev', 'lngDeg_prev', 'dist_prev']] = np.nan\n",
    "    df.loc[df['phone']!=df['phone_next'], ['latDeg_next', 'lngDeg_next', 'dist_next']] = np.nan\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe61d2",
   "metadata": {},
   "source": [
    "## phone mean prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a26c02c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@noglobal()\n",
    "def make_lerp_data(df_arg):\n",
    "    \"\"\"\n",
    "        Generate interplolated lat,lng values for different phone times in the same collection.    \n",
    "    \"\"\"\n",
    "    df = df_arg.copy()\n",
    "    \n",
    "    org_columns = df.columns\n",
    "        \n",
    "    time_list = df[[\"collectionName\",\"millisSinceGpsEpoch\"]].drop_duplicates()\n",
    "    phone_list = df[[\"collectionName\",\"phoneName\"]].drop_duplicates()\n",
    "    tmp = time_list.merge(phone_list,on=\"collectionName\",how = \"outer\")\n",
    "    \n",
    "    lerp_df = tmp.merge(df,on=[\"collectionName\",\"millisSinceGpsEpoch\",\"phoneName\"],how=\"left\")\n",
    "    lerp_df[\"phone\"] = lerp_df[\"collectionName\"] + \"_\" + lerp_df[\"phoneName\"] \n",
    "    lerp_df = lerp_df.sort_values([\"phone\",\"millisSinceGpsEpoch\"]);\n",
    "            \n",
    "    lerp_df['latDeg_prev'] = lerp_df['latDeg'].shift(1)\n",
    "    lerp_df['latDeg_next'] = lerp_df['latDeg'].shift(-1)\n",
    "    lerp_df['lngDeg_prev'] = lerp_df['lngDeg'].shift(1)\n",
    "    lerp_df['lngDeg_next'] = lerp_df['lngDeg'].shift(-1)\n",
    "    lerp_df['phone_prev'] = lerp_df['phone'].shift(1)\n",
    "    lerp_df['phone_next'] = lerp_df['phone'].shift(-1)\n",
    "    lerp_df['time_prev'] = lerp_df['millisSinceGpsEpoch'].shift(1)\n",
    "    lerp_df['time_next'] = lerp_df['millisSinceGpsEpoch'].shift(-1)\n",
    "    \n",
    "    lerp_df = lerp_df[(lerp_df['latDeg'].isnull())&(lerp_df['phone']==lerp_df['phone_prev'])&(lerp_df['phone']==lerp_df['phone_next'])].copy()\n",
    "    \n",
    "    \n",
    "    lerp_df['latDeg'] = lerp_df['latDeg_prev'] + ((lerp_df['latDeg_next'] - lerp_df['latDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    lerp_df['lngDeg'] = lerp_df['lngDeg_prev'] + ((lerp_df['lngDeg_next'] - lerp_df['lngDeg_prev']) * ((lerp_df['millisSinceGpsEpoch'] - lerp_df['time_prev']) / (lerp_df['time_next'] - lerp_df['time_prev']))) \n",
    "    \n",
    "    lerp_df = lerp_df[~lerp_df['latDeg'].isnull()]\n",
    "    \n",
    "    \n",
    "\n",
    "    return lerp_df[org_columns]\n",
    "    \n",
    "@noglobal()\n",
    "def calc_mean_pred(df, lerp_df):\n",
    "    '''\n",
    "    Make a prediction based on the average of the predictions of phones in the same collection.\n",
    "    '''\n",
    "    add_lerp = pd.concat([df, lerp_df])\n",
    "    mean_pred_result = add_lerp.groupby(['collectionName', 'millisSinceGpsEpoch'])[['latDeg', 'lngDeg']].mean().reset_index()\n",
    "    mean_pred_df = df[['collectionName', 'phoneName', 'millisSinceGpsEpoch']].copy()\n",
    "    mean_pred_df = mean_pred_df.merge(mean_pred_result[['collectionName', 'millisSinceGpsEpoch', 'latDeg', 'lngDeg']], on=['collectionName', 'millisSinceGpsEpoch'], how='left')\n",
    "    return mean_pred_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "193425ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:01<00:00, 51.21it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084ecaa5266142b786414a850526633d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/73 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_dataset = train_df\n",
    "target_columns_all = target_dataset.columns\n",
    "\n",
    "train_ro = outlier_correlation(train_df)\n",
    "\n",
    "\n",
    "pd_list = []\n",
    "for key,each_df in tqdm(train_ro.groupby(\"phone\")):\n",
    "    kf_ = generate_kalmanfilter()    \n",
    "    num = each_df[[\"latDeg\",\"lngDeg\"]].to_numpy()    \n",
    "    each_df[[\"latDeg\",\"lngDeg\"]] = apply_kalmanfilter(num,kf_)\n",
    "    pd_list.append(each_df)\n",
    "\n",
    "train_ro = pd.concat(pd_list,axis=0).sort_index()\n",
    "    \n",
    "train_ro[\"collectionName\"] = train_ro[\"phone\"].apply(lambda x:x.split(\"_\")[0])\n",
    "train_ro[\"phoneName\"] = train_ro[\"phone\"].apply(lambda x:x.split(\"_\")[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "404ee9ac",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from external_lib.phone_mean_prediction import phone_mean_prediction\n",
    "\n",
    "train_tmp = train_df\n",
    "\n",
    "\n",
    "\n",
    "train_mean_pread = phone_mean_prediction(train_tmp)\n",
    "train_mean_pread[\"phone\"] = train_mean_pread[\"collectionName\"] + train_mean_pread[\"phoneName\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa6a0979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "適用前 5.287859611805194\n",
      "適用後 4.771118181425187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "latDeg    0\n",
       "lngDeg    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from external_lib.evaluation_function import evaluate_function\n",
    "\n",
    "\n",
    "train_df[\"err\"] = calc_haversine(train_df[\"latDeg\"],train_df[\"lngDeg\"],train_df[\"latDeg_gt\"],train_df[\"lngDeg_gt\"])\n",
    "print(\"適用前\",evaluate_function(train_df,\"err\"))\n",
    "train_df[\"err\"] = calc_haversine(train_mean_pread[\"latDeg\"],train_mean_pread[\"lngDeg\"],train_df[\"latDeg_gt\"],train_df[\"lngDeg_gt\"])\n",
    "print(\"適用後\",evaluate_function(train_df,\"err\"))\n",
    "\n",
    "\n",
    "train_mean_pread[[\"latDeg\",\"lngDeg\"]].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd94209e",
   "metadata": {},
   "source": [
    "sample_sub = pd.read_csv(\"/work/data/input/google-smartphone-decimeter-challenge/sample_submission.csv\")\n",
    "sample_sub[\"latDeg\"] = train_mean_pread[\"latDeg\"]\n",
    "sample_sub[\"lngDeg\"] = train_mean_pread[\"lngDeg\"]\n",
    "sample_sub.to_csv(\"./test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
